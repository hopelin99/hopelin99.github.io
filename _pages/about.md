---
permalink: /
title: "Hongpeng Lin"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Welcome! I am a 3rd-year master student of Artificial Intelligence at [Gaoling School of Artificial Intelligence](http://ai.ruc.edu.cn/english), [Renmin University of China](https://www.ruc.edu.cn/en). I'm advised by Prof. [Ruihua Song](https://gsai.ruc.edu.cn/addons/teacher/index/info.html?user_id=0&ruccode=ATNUbVJhBjJRNgY3UDQFMg%3D%3D&ln=en), working on Natural Language Processing (NLP) and Multi-modal Dialogue. Prior to that, I completed my B.Eng. from School of Computer Science and Technology, [Xidian University](https://en.xidian.edu.cn/).

Email: [hopelin@ruc.edu.cn](mailto:hopelin@ruc.edu.cn) / [CV](https://hopelin99.github.io/assets/CV_Hongpeng_Lin.pdf) (Last updated in Apr. 2024)

## Research Interests
My research interests are in Natural Language Processing and Multi-modal Understanding, with the hope of making machines perceive, understand, and express like humans. 

Currently, my research focus is committed to adversarial robustness studies (jailbreaking LLMs and mitigation), long video understanding (natural language query localization), and creative multi-modal text generation (humor and association).

**I am open for collaborations in research. Also, I am looking for potential Ph.D. or RA. positions.**


## News
**01/2024** &nbsp;&nbsp;&nbsp;&nbsp; Checkout our new papers on how to [persuade LLMs to jailbreak them](https://chats-lab.github.io/persuasive_jailbreaker/) with a success rate of **92%**.


<video src="https://github.com/CHATS-lab/persuasive_jailbreaker/assets/61967882/3c04d83c-564d-40a5-87e8-423e0d377012" controls="controls" style="max-width: 730px;"></video>



<br>
**08/2023** &nbsp;&nbsp;&nbsp;&nbsp; Our paper "TikTalk" on multi-modal dialogue is accepted by ACM MM 2023!

## Papers

* How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs<br>Yi Zeng\*, **Hongpeng Lin\*** (lead authors), Jingwen Zhang, Diyi Yang, Ruoxi Jia*, Weiyan Shi\* (co-supervise)<br>arXiv, [Project](https://chats-lab.github.io/persuasive_jailbreaker/) [Paper](https://arxiv.org/abs/2401.06373) [Code](https://github.com/CHATS-lab/persuasive_jailbreaker)

  

* TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World
<br>
**Hongpeng Lin\***, Ludan Ruan\*, Wenke Xia\*, Peiyu Liu, Jingyuan Wen, Yixin Xu, Di Hu, Ruihua Song, Wayne Xin Zhao, Qin Jin, Zhiwu Lu
<br>
*ACM MM 2023(Oral)* &nbsp;&nbsp; [Project](https://ruc-aimind.github.io/projects/TikTalk/) [Paper](https://dl.acm.org/doi/abs/10.1145/3581783.3612425) [Code](https://github.com/RUC-AIMind/TikTalk)


## Service

* *Conference reviewer*: EMNLP, ACM MM, CVPR







